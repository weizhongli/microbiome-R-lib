## ==============================================================================
## Some useful R functions, that can be used together with data from ngomicswf
##
## program written by
##                                      Weizhong Li, J. Craig Venter Institute
##                                      wli@jcvi.org
##                                      http://weizhongli-lab.org
## ==============================================================================

# in case installaiton of some package fail
# try install some dependant package from Linux
# e.g. sudo apt-get install libnlopt-dev

library(FactoMineR);
library(vegan);
library(ggdendro);
library(grid);
library(gridExtra);
library(ggplot2);
library(reshape2);
library(dendextend);
library(sm);
library(cluster);
library(plyr);
library(readr)
library(dplyr)
library(tidyr)
library(printr)
library(RColorBrewer)
library(randomForest)
library(ROCR)
library(pheatmap)
#### network analysis
library(igraph)
library(qgraph)
library(psych)

#### limma through bioconductor
#### if (!requireNamespace("BiocManager", quietly = TRUE))
####    install.packages("BiocManager")
#### BiocManager::install()
#### BiocManager::install(c("limma"))
library(limma)
#### function list:


#### reference data
#### generated by work/refseq-genome.R
load("/Users/wli/UNIX/R-lib/metaLIB.RData")


#### add a pseudocount and return log10
#### min.f pseudocount = min(x>0) / min.f 
log10e <- function(x, min.f = 2) {
  pseudocount = min( x[x>0] ) / min.f
  log10(x + pseudocount)
}
log2e <- function(x, min.f = 2) {
  pseudocount = min( x[x>0] ) / min.f
  log2(x + pseudocount)
}
loge <- function(x, min.f = 2) {
  pseudocount = min( x[x>0] ) / min.f
  log(x + pseudocount)
}


######## given a sample-feature table, here are some common plots
#### a simple color func
mycol.s0 <- function(topn, pal.set = "Dark2") {
  pal.n = brewer.pal.info[pal.set, "maxcolors"]
  getPalette = colorRampPalette(brewer.pal(pal.n, pal.set))
  col.n = as.integer(topn/pal.n)+1
  col1 = getPalette( pal.n * col.n )
  col1 = col1 %>% matrix(ncol=pal.n) %>% t() %>% as.vector()
  col1
}

#### Set1, Set2, Set3, Dark2, Accent
mycol <- function(topn, pal.set = "Dark2") {
  n = brewer.pal.info[pal.set, "maxcolors"]
  m = 1 + as.integer(topn / n) + c(1,0)[ 1+ as.integer( topn%%n > 0) ]
  topn1 = m * n
  getPalette = colorRampPalette(brewer.pal(n, pal.set))
  col1 = getPalette( topn1 )
  col1 = col1 %>% matrix(ncol=n) %>% t() %>% as.vector()
  col1[1:topn]
}

#### given a vector x, retunr a vector of colors,
#### same feature will have same color
feature_2_col <- function(x, pal.set = "Dark2") {
  tib1 = tibble(id = x)
  tib2 = tibble(id = unique(x)) %>% arrange(id) %>% mutate(n = row_number())
  topn = nrow(tib2)
  
  n = brewer.pal.info[pal.set, "maxcolors"]
  m = 1 + as.integer(topn / n) + c(1,0)[ 1+ as.integer( topn%%n > 0) ]
  topn1 = m * n
  getPalette = colorRampPalette(brewer.pal(n, pal.set))
  col1 = getPalette( topn1 )
  col1 = col1 %>% matrix(ncol=n) %>% t() %>% as.vector()
  
  tib2 = tib2 %>% mutate(col = col1[1:topn])
  tib1 = tib1 %>% inner_join(tib2)
  tib1$col
}


#### x sample-feature tibble, features may be pre-sorted for topn to work
#### sample_ann: sample label, a tibble, where 1st column is sample_id, 2nd column is sample label
#### feature_ann: feature label, a tibble, where 1st column is feature, 2nd column is feature label
#### other features, if True, then sum non-topn feature
feature_barplot <- function(x, topn=ncol(x)-1, sample_ann=NULL, feature_ann=NULL, labx="Sample", laby="Abundance", 
                            legend_title="feature", subtitle="", other_features = F, pal.set="Dark2") {
  colnames(x)[1] = "sample_id"
  if (topn > ncol(x)-1) {
    topn = ncol(x)-1
  }
  df = x[,1:(topn+1)]
  ff = colnames(df)[-1]

  y1 = tibble(sample_id = x$sample_id)
  if (ncol(x)-1 > topn) {
    if (other_features) {
      y1 = tibble(sample_id = x$sample_id, other=apply(x %>% dplyr::select((topn+2):ncol(x)) , 1, sum ) )
      ff = c(ff,"other")
    }
  }

  y = gather( x[,1:(topn+1)] %>% inner_join(y1), key=feature, value=abundance, -sample_id) %>%
      mutate(feature = factor(feature, levels=rev(ff)))
  ## above mutate to factor to make sure features are ordered by abundance

  if (! is.null(sample_ann)) {
    y = sample_ann %>% dplyr::select(1,2) %>% inner_join(y) %>% dplyr::select(-1)
    colnames(y)[1] = "sample_id"
  }

  if (! is.null(feature_ann)) {
    y = feature_ann %>% dplyr::select(1,2) %>% inner_join(y) %>% dplyr::select(-1)
    colnames(y)[1] = "feature"
  }

  ggplot(y, aes(x=sample_id, y=abundance))+geom_col(aes(fill=feature)) +
     labs(y=laby,  x=labx, subtitle=subtitle) +
     theme(axis.text.x=element_text(angle=90, hjust=1), legend.position="right") +
     scale_fill_manual(values = mycol(length(ff), pal.set=pal.set)) +
     guides(fill=guide_legend(title= legend_title))
}

#### x sample-feature tibble, features may be pre-sorted for topn to work
#### sample_group sample label, a tibble, where 1st column is sample_id, 2nd column is sample label
#### if draw.plot = F, return y.df
feature_nmds_plot <- function(x, topn=ncol(x)-1, sample_group=NULL, legend_title="group", rand.seed=42, draw.ellipse = T, draw.plot=T) {
  colnames(x)[1] = "sample_id"
  set.seed(rand.seed)

  if (topn > ncol(x)-1) {
    topn = ncol(x)-1
  }
  df = x[,1:(topn+1)]
  y = metaMDS( vegdist( df  %>% dplyr::select(-1)) )
  y.df = cbind( tibble(sample_id=df$sample_id), y$points)

  if (draw.plot == F) {
    return(y.df %>% as_tibble())
  }
  if (! is.null(sample_group)) {
    y.df = sample_group %>% dplyr::select(1,2) %>% inner_join(y.df)
    colnames(y.df)[2] = "group"
    g = ggplot(y.df, aes(x=MDS1, y=MDS2, colour=group)) +
      geom_point(size=2.0) + labs(x="NMDS1", y="NMDS2") +
      guides(colour = guide_legend(title=legend_title))
    if (draw.ellipse) g=g+ stat_ellipse()
    g
  }
  else {
    ggplot(y.df, aes(x=MDS1, y=MDS2)) +
    geom_point(size=2.0) + labs(x="NMDS1", y="NMDS2")
  }
}

feature_PCA_plot <- function(x, topn=ncol(x)-1, sample_group=NULL, legend_title="group", rand.seed=42, draw.ellipse = T) {
  colnames(x)[1] = "sample_id"
  set.seed(rand.seed)

  if (topn > ncol(x)-1) {
    topn = ncol(x)-1
  }
  df = x[,1:(topn+1)]

  pca = PCA(df %>% dplyr::select(-1), scale.unit = F, graph = F)
  y.df = cbind( tibble(sample_id=df$sample_id), pca$ind$coord)

  pc1 = as.integer(pca$eig[1,2]*100) / 100
  pc2 = as.integer(pca$eig[2,2]*100) / 100
  labx = paste("PC1 (", pc1, "%)", sep="")
  laby = paste("PC2 (", pc2, "%)", sep="")

  if (! is.null(sample_group)) {
    y.df = sample_group %>% dplyr::select(1,2) %>% inner_join(y.df)
    colnames(y.df)[2] = "group"
    g = ggplot(y.df, aes(x=Dim.1, y=Dim.2, colour=group)) +
      geom_point(size=2.0) + labs(x=labx, y=laby) +
      guides(colour = guide_legend(title=legend_title))
    if (draw.ellipse) g=g+ stat_ellipse()
    g
  }
  else {
    ggplot(y.df, aes(x=Dim.1, y=Dim.2)) +
    geom_point(size=2.0) + labs(x=labx, y=laby)
  }
}

feature_div_plot <- function(x, topn=ncol(x)-1, sample_group=NULL, legend_title="group", rand.seed=42, draw.ellipse = T) {
  colnames(x)[1] = "sample_id"
  set.seed(rand.seed)

  if (topn > ncol(x)-1) {
    topn = ncol(x)-1
  }
  df = x[,1:(topn+1)]

  y.df = sample_div(df)
  labx = "Richness"
  laby = "Shannon diversity index"

  if (! is.null(sample_group)) {
    y.df = sample_group %>% dplyr::select(1,2) %>% inner_join(y.df)
    colnames(y.df)[2] = "group"
    g = ggplot(y.df, aes(x=richness, y=shannon, colour=group)) +
      geom_point(size=2.0) + labs(x=labx, y=laby) +
      guides(colour = guide_legend(title=legend_title))
    if (draw.ellipse) g=g+ stat_ellipse()
    g
  }
  else {
    ggplot(y.df, aes(x=richness, y=shannon)) +
    geom_point(size=2.0) + labs(x=labx, y=laby)
  }
}


#### x sample-feature tibble, features may be pre-sorted for topn to work
#### sample_ann: sample label, a tibble, where 1st column is sample_id, 2nd column is sample label
#### feature_ann: feature label, a tibble, where 1st column is feature, 2nd column is feature label
#### trans_func, transform function, such as log, log10, or function(x){ log10(x+10)}
feature_heatmap <- function(x, topn=ncol(x)-1, trans_func=NULL, sample_ann=NULL, feature_ann=NULL, sample_lab = NULL, feature_lab = NULL, 
                            direction = 1, subtitle="", max_len=40, show_colnames = T, show_rows = F, ...) {
  colnames(x)[1] = "sample_id"
  if (topn > ncol(x)-1) {
    topn = ncol(x)-1
  }
  df = x[,1:(topn+1)]
  features = colnames(df)[-1]
  samples  = x$sample_id

  x.mat = as.matrix( df %>% select(-1) )
  if (! is.null(trans_func)) {
    x.mat = trans_func(x.mat)
  }
  rownames(x.mat) = samples

  lab_samples = NULL
  if (! is.null(sample_lab)) {
    tmp = x %>% dplyr::select(1) %>% inner_join(sample_lab %>% dplyr::select(1,2))
    colnames(tmp)[2]= "lab"
    lab_samples = tmp$lab %>% as.vector()
  }  
  lab_features = NULL
  if (! is.null(feature_lab)) {
    tmp = tibble(name=features) %>% inner_join(feature_lab %>% dplyr::select(1,2))
    colnames(tmp)[2]= "lab"
    lab_features = substr(tmp$lab %>% as.vector(), 1, max_len)
  }
  if (! is.null(sample_ann)) {
    sample_ann = x %>% dplyr::select(1) %>% inner_join(sample_ann %>% dplyr::select(1,2)) %>% dplyr::select(-1) %>% as.data.frame()
    rownames(sample_ann) = samples;
  }
  if (! is.null(feature_ann)) {
    feature_ann = tibble(name=features) %>% inner_join(feature_ann %>% dplyr::select(1,2)) %>% dplyr::select(-1) %>% as.data.frame()
    rownames(feature_ann) = features;
  }

  if (direction == 1) {
    pheatmap(x.mat, annotation_row = sample_ann, labels_row=lab_samples,
                    annotation_col = feature_ann, labels_col=lab_features, main=subtitle, show_colnames = show_colnames, show_rows=show_rows, ...)
  }
  else {
    pheatmap(t(x.mat), annotation_col = sample_ann, labels_col=lab_samples,
                       annotation_row = feature_ann, labels_row=lab_features, main=subtitle, show_colnames = show_colnames, show_rows=show_rows, ...)
  }

##    try below to itilic colnames
##    newnames <- lapply(colnames(z.df.mat), function(x) bquote(italic(.(x))))
##    pheatmap(z.df.mat, cluster_rows = F, cluster_cols = F, main="Species increased in cancer", fontsize = 10, labels_col = colnames(z.df.mat))

}


#### x sample-feature tibble, features may be pre-sorted for topn to work
#### return heatmap for samples, with color indicating pairwise sample distance or correlation
#### dist_fun c("vegdist","cor")
#### dist_method if vegdist then c("manhattan", "euclidean", "canberra", "clark", "bray", "kulczynski", etc)
####        else if cor     then c("pearson", "kendall", "spearman")
feature_heatmap_samples <- function(x, topn=ncol(x)-1, sample_ann=NULL, sample_lab = NULL, dist_fun="vegdist", dist_method=NA) {
  colnames(x)[1] = "sample_id"
  if (topn > ncol(x)-1) {
    topn = ncol(x)-1
  }
  df = x[,1:(topn+1)]

  if (dist_fun == "vegdist") {
    if (is.na(dist_method)) {
      mat = 1 - as.matrix(vegdist(df %>% dplyr::select(-1)))
    }
    else {
      mat = 1 - as.matrix(vegdist(df %>% dplyr::select(-1), method=dist_method))
    }
  }
  else {
    if (is.na(dist_method)) {
      mat = cor(t(df %>% dplyr::select(-1)))
    }
    else {
      mat = cor(t(df %>% dplyr::select(-1)), method=dist_method)
    }
  }

  if (! is.null(sample_lab)) {
    tmp = x %>% dplyr::select(1) %>% inner_join(sample_lab %>% dplyr::select(1,2))
    colnames(tmp)[2]= "lab"
    lab_samples = tmp$lab
  }
  else {
    lab_samples = x$sample_id
  }

  if (! is.null(sample_ann)) {
    sample_ann = x %>% dplyr::select(1) %>% inner_join(sample_ann) %>% dplyr::select(-1) %>% as.data.frame()
    #rownames(sample_ann) = x$sample_id;
  }
  pheatmap(mat, annotation_row = sample_ann, labels_row=lab_samples)
}

#### x sample-feature tibble, features may be pre-sorted for topn to work
#### sample_2_group , tibble, first column is sample, 2nd column is group
#### feature, tibble, first column is subset of features in x
####                  other columns can be p.value, label
#### col.p column for p.value in feature
#### col.lab column for feature label
feature_2g_boxplot <- function(x, sample_2_group, feature, col.p = NA, col.lab = NA, 
                               lab.x="Feature", lab.y="Abundance", subtitle="") {
  colnames(x)[1] = "sample_id"
  colnames(feature)[1] = "name" 
  y = x %>% dplyr::select(c("sample_id", feature$name ))
  colnames(sample_2_group)[1] = "sample_id";
  colnames(sample_2_group)[2] = "group";
  sample_2_group = sample_2_group %>% mutate(group = as.factor(group))

  df = gather(y, key=name, value=abundance, -sample_id) %>% inner_join(sample_2_group)

  if (! is.na(col.p)) {
    colnames(feature)[col.p] = "p.value"
    feature = feature %>% arrange(p.value)
    sorted.feature = feature$name
    df = df %>% mutate(name = factor(name, levels=sorted.feature))
    max = max(df$abundance)
  }
  else { #### 
    df = df %>% mutate(name = factor(name, levels=feature$name))
  }

  if (! is.na(col.lab)) {
    colnames(feature)[col.lab] = "label"
    df = df %>% inner_join( feature %>% dplyr::select(c("name","label")) ) %>% mutate(name = label)
  }

  g = ggplot(df, aes(x=name, y=abundance, colour=group)) + geom_boxplot(outlier.size = 0) + 
    geom_point(pch = 21, position = position_jitterdodge()) +
    theme(axis.text.x=element_text(angle=90, hjust=1)) + 
    labs(x=lab.x, y=lab.y, subtitle="")

  if (! is.na(col.p)) {
    g = g + geom_label(data=as.data.frame(feature), inherit.aes=F, aes(x=name, y=max, label=paste("p= ", as.character(signif(p.value, 2)), sep="")))
  }
  g
}


#### x sample-feature tibble, features may be pre-sorted for topn to work
#### bin sample into clusters based on
####     1. cutoff.d clustering threshold 
#### OR
####     2. cutoff.k number of target clusters
#### OR no cutree
sample_hclust <- function(x, topn=NA, dist_fun="vegdist", dist_method=NA, cutoff.d = NA, cutoff.k = NA) {
  colnames(x)[1] = "sample_id"
  if (is.na(topn)) {
    topn = ncol(x)-1
  } else if (topn > ncol(x)-1) {
    topn = ncol(x)-1
  }
  df = x[,1:(topn+1)]

  if (dist_fun == "vegdist") {
    if (is.na(dist_method)) {
      dist.mat = as.matrix(vegdist(df %>% dplyr::select(-1)))
    } else {
      dist.mat = as.matrix(vegdist(df %>% dplyr::select(-1), method=dist_method))
    }
  } else {
    if (is.na(dist_method)) {
      dist.mat = cor(t(df %>% dplyr::select(-1)))
    } else {
      dist.mat = cor(t(df %>% dplyr::select(-1)), method=dist_method)
    }
    dist.mat = (1-dist.mat)/2
  }
  rownames(dist.mat) = x$sample_id
  colnames(dist.mat) = x$sample_id

  hr = hclust(as.dist(dist.mat))
  if (! is.na(cutoff.k)) {
    hr.cut = cutree(hr, k = cutoff.k)
  } else if (! is.na(cutoff.d)) {
    hr.cut = cutree(hr, h = cutoff.d)
  } else {
    hr.cut = cutree(hr, h = 0)
  }
  list(sample.bin = tibble(sample_id = names(hr.cut), bin = hr.cut) %>% mutate(bin=factor(bin)) %>% arrange(bin),
       plot = ggdendrogram(hr))
}

#### x sample-feature tibble
#### return correlation tibble with r, p, various p.adjust
#### method="pearson" is the default value. The alternatives to be passed to cor are "spearman" and "kendall"
feature_corr <- function(x, colname1="sp1", colname2="sp2", ...) {
  c1 = corr.test( x %>% dplyr::select(-1), ... )
  c1$p[upper.tri(c1$p)] = 2
  c1$r[upper.tri(c1$r)] = 2
  cr = c1$r %>% as_tibble() %>% mutate(sp1 = rownames(c1$r)) %>% gather(key=sp2, value=r, -sp1)
  cp = c1$p %>% as_tibble() %>% mutate(sp1 = rownames(c1$p)) %>% gather(key=sp2, value=p, -sp1) %>% 
    filter(p<2) %>% filter(sp1 != sp2) %>% arrange(p) %>%
    mutate(p.holm       = p.adjust(p, method = "holm")) %>% #### holm is same as hochberg
    mutate(p.hommel     = p.adjust(p, method = "hommel")) %>%
    mutate(p.bonferroni = p.adjust(p, method = "bonferroni")) %>%
    mutate(p.BH.fdr     = p.adjust(p, method = "BH")) %>%  #### BH is same as fdr
    mutate(p.BY         = p.adjust(p, method = "BY")) %>%
    mutate(qvalue       = qvalue(p)$qvalues)

  colnames(cr)[1] = colname1
  colnames(cr)[2] = colname2
  colnames(cp)[1] = colname1
  colnames(cp)[2] = colname2
  cr %>% inner_join(cp)
}

#### x sample-feature tibble for feature set A, e.g. species
#### y sample-feature tibble for feature set B, e.g. metabolite
#### return correlation tibble with r, p, various p.adjust
#### method="pearson" is the default value. The alternatives to be passed to cor are "spearman" and "kendall"
feature_AB_corr <- function(x, y, colname1="sp1", colname2="sp2", ...) {
  z = x %>% dplyr::select(1) %>% inner_join( y %>% dplyr::select(1) )
  x1 = z %>% inner_join(x)
  y1 = z %>% inner_join(y)

  c1 = corr.test( x1 %>% dplyr::select(-1), y1 %>% dplyr::select(-1), adjust = "none", ... )
  cr = c1$r %>% as_tibble() %>% mutate(sp1 = rownames(c1$r)) %>% gather(key=sp2, value=r, -sp1)
  cp = c1$p %>% as_tibble() %>% mutate(sp1 = rownames(c1$p)) %>% gather(key=sp2, value=p, -sp1) %>%
    filter(p<2) %>% filter(sp1 != sp2) %>% arrange(p) %>%
    mutate(p.holm       = p.adjust(p, method = "holm")) %>% #### holm is same as hochberg
    mutate(p.hommel     = p.adjust(p, method = "hommel")) %>%
    mutate(p.bonferroni = p.adjust(p, method = "bonferroni")) %>%
    mutate(p.BH.fdr     = p.adjust(p, method = "BH")) %>%  #### BH is same as fdr
    mutate(p.BY         = p.adjust(p, method = "BY")) ####  %>%
    #### mutate(qvalue       = qvalue(p)$qvalues), something wrong with qvalue, it required the input has a 1.0 value

  q1 = c(1.0, cp$p) %>% qvalue()
  cp = cp %>% mutate(qvalue = q1$p[-1])

  colnames(cr)[1] = colname1
  colnames(cr)[2] = colname2
  colnames(cp)[1] = colname1
  colnames(cp)[2] = colname2
  cr %>% inner_join(cp)
}


#### call vegdist
sample_dist <- function(x, ...) {
  colnames(x)[1] = "sample_id"
  ids = x$sample_id

  y = x %>% dplyr::select(-1) %>% as.data.frame()
  rownames(y) = ids
  vegdist(y, ...)
}

#### input x: feature table, first column is sample_id
#### meta: meta table, first column is sample_id,
#### output pairwise dist, in long form, with meta info for each sample
####     col: sample_id.i, sample_id.j, dist, meta1.i, meta1.j, meta2.i, meta2.j
sample_dist_meta <- function(x, meta, topn = NA, dist_fun="vegdist", dist_method=NA) {
  colnames(x)[1] = "sample_id"
  if (is.na(topn)) {
    topn = ncol(x)-1
  } else if (topn > ncol(x)-1) {
    topn = ncol(x)-1
  }
  df = x[,1:(topn+1)]

  if (dist_fun == "vegdist") {
    if (is.na(dist_method)) {
      dist.mat = as.matrix(vegdist(df %>% dplyr::select(-1)))
    } else {
      dist.mat = as.matrix(vegdist(df %>% dplyr::select(-1), method=dist_method))
    }
  } else {
    if (is.na(dist_method)) {
      dist.mat = cor(t(df %>% dplyr::select(-1)))
    } else {
      dist.mat = cor(t(df %>% dplyr::select(-1)), method=dist_method)
    }
    dist.mat = (1-dist.mat)/2
  }
  rownames(dist.mat) = x$sample_id
  colnames(dist.mat) = x$sample_id
  dist.mat[upper.tri(dist.mat)] = NA
  dist.pair = dist.mat %>% as.data.frame() %>% as_tibble() %>% 
    mutate(sample_id.i = x$sample_id) %>% gather(key=sample_id.j, value=dist, -sample_id.i)
  dist.pair = dist.pair %>% filter( !is.na(dist) ) %>% filter(sample_id.i != sample_id.j)

  meta.i = meta
  colnames(meta.i) = paste( colnames(meta), "i", sep=".")
  meta.j = meta
  colnames(meta.j) = paste( colnames(meta), "j", sep=".")
  dist.pair %>% inner_join(meta.i) %>% inner_join(meta.j)
}

######## read in various tables
#### ranks, c("phylum", "genus", "species") 
#### cutoff_abs, abundance cutoff for species
#### order_species_by, order species by decreasing value of this function apply to all samples
#### cutoff_abs_sum, after species ordering, species at which the cumulated abs < cutoff will be kept, otherwise deleted
read_taxon_tibble <- function (dir, ranks=c("phylum", "genus", "species"), cutoff_abs=0.0001, cutoff_abs_sum=0.99, order_species_by=sum, file_prefix="taxon-") {
  col_start = list();
  col_start[["phylum"]]  = 5;
  col_start[["genus"]]   = 9;
  col_start[["species"]] = 10;
  col_start[["toprank"]] = 11;

  fun_list=list();
  for (tf in ranks) {
    df   = read_tsv(paste(dir, paste(file_prefix, tf, ".tsv", sep=""), sep="/"))
    colnames(df)[ col_start[[tf]] -1 ] = 'name'
    colnames(df)[ 1 ] = 'tax_id'
    df  = df %>% group_by(name) %>% filter(row_number() == 1) %>% ungroup()
    cols = colnames(df)
    i1   = col_start[[tf]]
    i2   = length(cols)
    samples = cols[ i1:i2 ]

    df = df %>% filter(! is.na(name))

    feature = df %>% dplyr::select(1:(i1-1)) %>%
      mutate(max = as.vector( apply(df[, i1:i2], 1, max       ))) %>%
      mutate(sum = as.vector( apply(df[, i1:i2], 1, order_species_by )) / length(samples) )

    abs = as_tibble(t(df %>% dplyr::select(i1:i2)))
    colnames(abs) = feature$name
    abs = abs %>% mutate(sample_id = samples) %>% dplyr::select(c("sample_id", df$name))

    if (tf == "phylum") { #### remove taxid <0
      feature = feature %>% filter(tax_id>0)
      abs = abs %>% dplyr::select(c("sample_id", feature$name))
    }

    #### filter cutoff_abs
    feature = feature %>% filter(max >= cutoff_abs)
    #### top species
    feature = feature %>% dplyr::arrange(desc(sum)) %>%
      mutate(top = cumsum(feature$sum) <= cutoff_abs_sum) %>%
      filter(top == T)

    abs = abs %>% dplyr::select(c("sample_id", feature$name))
    fun_list[[tf]]=abs
    fun_list[[paste(tf,"_info",sep="")]] = feature
  }
  fun_list;
}

#### read in qc.tsv, taxon-superkingdom-whost.tsv.tsv
read_taxon_qc_kindom <- function (dir, files=c("qc","taxon-superkingdom-whost")) {
  fun_list=list();
  for (tf in files) {
    df   = read_tsv(paste(dir, paste(tf, "tsv", sep="."),  sep="/"))
    if (tf == 'taxon-superkingdom-whost') {
      df = df %>% dplyr::select(-1)
    }
    samples = colnames(df)[-1]
    colnames(df)[1] = 'name'
    abs = as_tibble(t(df %>% dplyr::select(-1)))
    colnames(abs) = df$name
    abs = abs %>% mutate(sample_id = samples) %>% dplyr::select(c("sample_id", df$name))
    fun_list[[tf]]=abs
  }
  fun_list;
}


#### read in a single otu table
#### JCVI pipeline format
read_otu_tibble <- function (file, order_species_by=sum) {
  df = read_tsv(file)
  colnames(df)[1] = "OTU"
  otus = df$OTU

  samples = colnames(df)[-1]

  dft = as_tibble( t( df %>% dplyr::select(-1) ))
  colnames(dft) = otus
  dft = tibble(sample_id = samples) %>% inner_join(dft %>% mutate(sample_id=samples))
  feature = tibble(name=otus, sum = as.vector( apply(dft %>% dplyr::select(-1), 2, order_species_by))) %>% arrange(desc(sum))
  dft %>% select(c("sample_id", feature$name))
}

#### input x is a taxon table at different ranks, where feature can be OTU00001 etc
#### this function merger all OTUxxxxx into a single feature e.g. Other_OTUs
#### pattern: search pattern for columns e.g. OTU, Otu, which can match the columns
#### new.key: colname for the combined OTUs
taxon_tibble_merge_OTUs <- function(x, pattern, new.key = "Other_OTUs") {
  key_name = colnames(x)[1]
  feat_names = colnames(x)[-1]
  otu_names = grep(pattern, feat_names, value = T)
  non_otu_names = grep(pattern, feat_names, value=T, invert = T)
  y = x %>% select(key_name, non_otu_names) %>% 
    mutate(merged = x %>% select(otu_names) %>% apply(1, sum))
  colnames(y)[ dim(y)[2] ] = new.key
  y
}


#### read in a single feature table, allowing multiple columns of feature annotation
#### row for feature
#### column for samples
#### columns with all integer and double are considered samples
read_general_tibble <- function(file, key_col =1, order_species_by=sum) {
  df = read_tsv(file)
  colnames(df)[key_col] = "UUID"
  df  = df %>% group_by(UUID) %>% filter(row_number() == 1) %>% ungroup()
  df = df %>% dplyr::select("UUID") %>% inner_join(df)
  features = df$UUID
  col.keys = colnames(df)[-1]

  samples     = col.keys[  as.vector(sapply(col.keys, function(x) {typeof(df[[x]])})) %in% c("integer", "double") ]
  non_samples = col.keys[! as.vector(sapply(col.keys, function(x) {typeof(df[[x]])})) %in% c("integer", "double") ]

  df_info = df %>% dplyr::select(c("UUID", non_samples))
  colnames(df_info)[1] = "name"

  df_x = df %>% dplyr::select(c("UUID", samples))
  y    = tibble_t(df_x)
  colnames(y)[1] = "sample_id";
  y = y %>% order_feature(order_species_by= order_species_by)

  list(x=y, info=df_info)
}

#### read taxon tables converted from otu table and taxonomy by git/ngomicswf/NGS-tools/JCVI/jcvi-otu-to-tax.pl
read_taxon_tibble_16S <- function (dir, ranks=c("phylum", "genus", "species"), cutoff_abs=0, order_species_by=sum, file_prefix="taxon-16s") {
  col_start = list();
  col_start[["phylum"]]  = 2;
  col_start[["class"]]   = 3;
  col_start[["order"]]   = 4;
  col_start[["family"]]  = 5;
  col_start[["genus"]]   = 6;
  col_start[["species"]] = 7;

  fun_list=list();
  for (tf in ranks) {
    df   = read_tsv(paste(dir, paste(file_prefix, tf, "txt", sep="."), sep="/"))
    colnames(df)[ col_start[[tf]] -1 ] = 'name'
    df  = df %>% group_by(name) %>% filter(row_number() == 1) %>% ungroup()
    cols = colnames(df)
    i1   = col_start[[tf]]
    i2   = length(cols)
    samples = cols[ i1:i2 ]

    df = df %>% filter(! is.na(name))

    feature = df %>% dplyr::select(1:(i1-1)) %>%
      mutate(max = as.vector( apply(df[, i1:i2], 1, max       ))) %>%
      mutate(sum = as.vector( apply(df[, i1:i2], 1, order_species_by ))) %>%
      arrange(desc(sum))

    abs = as_tibble(t(df %>% dplyr::select(i1:i2)))
    colnames(abs) = feature$name
    abs = abs %>% mutate(sample_id = samples) %>% dplyr::select(c("sample_id", df$name))

    #### filter cutoff_abs
    feature = feature %>% filter(max >= cutoff_abs)

    abs = abs %>% dplyr::select(c("sample_id", feature$name))
    fun_list[[tf]]=abs
    fun_list[[paste(tf,"_info",sep="")]] = feature
  }
  fun_list;
}


#### return short name e.g. Escherichia coli => E. coli
#### input: vector of character
#### short_species_name
red_species_name <- function (x) {
  x = gsub("\\[|\\]", "", x, perl=T)  #### remove []
  gsub("^(.)\\S+ ","\\1.",x, perl=T)
}

#### when genus has NA in it
#### change it to "unnamed_genus_in_phylum_name"
taxon_fill_genus <- function(phylum, genus) {
  ifelse(is.na(genus), paste("unnamed_genus_in_", phylum, sep=""), genus)
}
#### given a list of taxa, merge less frequent taxa into one group called group.name
#### so that total number of distinct taxa is topn
#### e.g. taxon_merge_misc(genus, 10, "other_genera")
taxon_merge_misc <- function(genus, topn, group.name) {
  x = tibble(id = genus)
  x1 = x %>% group_by(id) %>% summarise(n=length(id), .groups="drop_last") 
  x = x %>% inner_join(x1) %>% arrange(desc(n)) %>% select(1)
  x1 = x %>% group_by(id) %>% filter(row_number()==1) %>% ungroup() %>% mutate(idx = row_number())
  x = x %>% inner_join(x1) 
  x = x %>% mutate(new.id = ifelse(x$idx >= topn, group.name, x$id ))
  x$new.id
}



#### given a feature table
#### calculate max, min, mean, median, sd, occurance
#### occurance need > cutoff
feature_info <- function(x, cutoff=0) {
  feature = colnames(x)[-1]
  tibble(name   = feature,
         max    = as.vector(apply(x%>%dplyr::select(-1), 2, max)),
         min    = as.vector(apply(x%>%dplyr::select(-1), 2, min)),
         mean   = as.vector(apply(x%>%dplyr::select(-1), 2, mean)),
         median = as.vector(apply(x%>%dplyr::select(-1), 2, median)),
         sd     = as.vector(apply(x%>%dplyr::select(-1), 2, sd)),
         occur  = as.vector(apply(x%>%dplyr::select(-1), 2, function(x){ sum(x>cutoff) } ) ))
}

#### after certain operation of feature table, e.g. removing some features
#### re normalize the abundance so that total abs of samples add up to target
normalize_feature_abs <- function(x, normalize_to=1) {
  sample_key = colnames(x)[1]
  colnames(x)[1] = "sample_id"
  samples = x$sample_id
  y = x %>% dplyr::select(-1) 
  #### avoid sum ==0
  sum1 = as.vector(apply(y, 1, sum))
  sum1[ sum1 == 0 ] = 1
  y = y / sum1
  y = y * normalize_to
  y = as_tibble(y) %>% mutate(sample_id = samples)
  y = x %>% dplyr::select(1) %>% inner_join(y)
  colnames(y)[1] = sample_key
  y
}


#### after certain operation of feature table
#### reorder features so that most abundant feature to the left
order_feature <- function(x, order_species_by=sum) {
  sample_key = colnames(x)[1]
  feature = tibble(name = colnames(x)[-1], sum=as.vector(apply(x%>%dplyr::select(-1), 2, order_species_by ))) %>%
      arrange(desc(sum))
  x %>% dplyr::select(c(sample_key, feature$name))
}

#### given a taxon tibble, first column is sample, other cols are taxon features
#### remove low abundance features so that total
#### abundance >= cutoff_abs
reduce_taxon_tib <- function(x, cutoff_abs=0.99) {
  y = tibble(name=colnames(x)[-1], total=apply(x %>% dplyr::select(-1), 2, sum)) %>% 
      arrange(desc(total)) %>% mutate(total = total / nrow(x))
  y = y %>% mutate(t1=cumsum(y$total), top = cumsum(y$total) <= cutoff_abs) %>%
      filter(top == T)
  x %>% dplyr::select(c(colnames(x)[1], y$name))
}

#### given a taxon tibble, first column is sample, other cols are taxon features
#### remove features that are zero (cutoff)
reduce_zero_feature <- function(x, cutoff = 0) {
  y = tibble(name=colnames(x)[-1], max=apply(x %>% dplyr::select(-1), 2, max)) %>%
      filter(max > cutoff)
  x %>% dplyr::select(c(colnames(x)[1], y$name))
}


#### given a taxon tibble, first column is sample, other cols are taxon features
#### remove rare features that exist in < cutoff of samples at above cutoff.abs abundance
reduce_rare_feature <- function(x, cutoff = 0, cutoff.abs = 0) {
  num_sample = nrow(x)

  t.func <- function(x) {
    sum(as.integer(x > cutoff.abs))
  }
  y = tibble(name=colnames(x)[-1], prevalence=apply(x %>% dplyr::select(-1), 2, t.func)) %>%
      filter(prevalence > cutoff * num_sample)
  x %>% dplyr::select(c(colnames(x)[1], y$name))
}


#### change the feature table to present / absent table
#### if value > 1 then 1 else 0
feature_tib_present_absent <- function(x, cutoff = 0) {
  y = x %>% dplyr::select(-1) %>% as.matrix()
  y[y >  cutoff] = 1
  y[y < 1      ] = 0
  x %>% dplyr::select(1) %>% cbind( y %>% as.data.frame() ) 
}


#### the input feature x, maybe normalized by mapped reads only, sum to 1.0
#### this function will apply r (total mapped reads / total reads) to the feature table
#### so that features will sum to portion of mapped reads
#### r is vector 
scale_feature_with_unmapped <- function(x, r) {
  n.sample = nrow(x)
  if (length(r) != n.sample) {
    warning("x and r not same length")
    return(x)
  }
  if (max(r) > 1) {
    warning("element of r is > 1")
    return(x)
  }
  if (min(r) < 0) {
    warning("element of r is < 0")
    return(x)
  }
  y = x;
  mat = matrix(rep(r, ncol(x)-1), nrow=n.sample)
  y[, 2:ncol(x)] = (y %>% select(-1)) * mat
  y
}


#### given a taxon tibble, first column is sample, other cols are features
#### the values are abundance
#### this function convert the abundance to rank, higher abundance -> lower rank (in front)
####
feature_abs_to_rank <- function(x) {
  y = x %>% dplyr::select(-1) %>% apply(1, rank) %>% t()
  y = y %>% apply(1, rev) %>% t()
  x %>% dplyr::select(1) %>% cbind(y) %>% as_tibble()
}


#### calc cumulative curve for multi groups
#### see info of cumulative_curve
#### input group, tibble, first col sample_id, 2nd col, sample_group
#### output, 3rd column group
cumulative_curve_multi_group <- function(x, sample_group, cutoff = 0, N = 20, rand.seed=42) {
  g1 = x %>% dplyr::select(1) %>% inner_join(sample_group %>% dplyr::select(1,2))
  colnames(g1)[2] = "grp"
  grps = unique(g1$grp)

  y = tibble(sample=character(0), total_feature=integer(0), group=character(0))

  for (i in grps) {
    x1 = x %>% inner_join( g1 %>% filter(grp ==i) %>% select(1))
    y = y %>% rbind( cumulative_curve(x1, cutoff, N, rand.seed) %>% mutate(group=i))
  }
  y
}

#### calc cumulative curve
#### input x, sample feature tibble
#### input N: number of times to shuffle sample, return the median of N results 
#### return tibble:
####   col1: total sample, col2: cumulative features
cumulative_curve <- function (x, cutoff = 0, N = 20, rand.seed=42) {
  K = nrow(x)
  y=matrix(nrow=K, ncol=N)
  set.seed(rand.seed)

  for (i in 1:N) {
    x1 = x %>% arrange(sample(K)) %>% dplyr::select(-1) #### shuffle samples, and unselect sample_id
    for (j in 1:K) {
      y[j, i] = sum(as.vector(apply(x1[1:j,], 2, max)) > cutoff)
    } 
  }

  curve = apply(y, 1, median)
  tibble(sample = 1:K, total_feature = sort(curve)) %>% mutate(total_feature = as.integer(total_feature))
}

#### feature reduction by co-abundance
#### correlated features (Pearson correlation) will be merged (defualt sum)
reduction_by_co_abs <- function (x, cutoff.d=0.1, merge_fun=sum) {
  colnames(x)[1] = "sample_id"
  #### r can be (-1, 1), convert to (0, 1)
  hr = hclust( as.dist(1 - (1+cor(x %>% dplyr::select(-1), method="pearson"))/2));
  hr.cut = cutree(hr, h = cutoff.d);
  feature.bin = tibble(name = names(hr.cut), bin = hr.cut) %>% arrange(bin)
  bin.no = max(feature.bin$bin);
  feature.abs = tibble(name=colnames(x)[-1], sum = as.vector(apply(x %>% dplyr::select(-1), 2, sum)))
  feature.bin = feature.bin %>% inner_join(feature.abs) %>% arrange(bin, desc(sum))

  feature.rep = feature.bin %>% group_by(bin) %>% filter(row_number() ==1) %>% ungroup() %>% select(1,2)
  colnames(feature.rep)[1] = "rep"
  feature.bin = feature.bin %>% inner_join(feature.rep)

  rep.size = feature.bin %>% select(2,4) %>% group_by(rep) %>% summarise_all(length)
  colnames(rep.size)[2] = "bin.size"
  feature.bin = feature.bin %>% inner_join(rep.size)

  y = as_tibble(t(x %>% dplyr::select(-1))) %>% mutate(name = colnames(x)[-1])
  y = feature.bin %>% dplyr::select(1,4) %>% inner_join(y)
  y = y %>% dplyr::select(-1) %>% group_by(rep) %>% summarise_all(merge_fun)
  reps = y$rep
  y = as_tibble(t(y %>% dplyr::select(-1)))
  colnames(y) = reps
  y = y %>% mutate(sample_id = x$sample_id) %>% dplyr::select(c("sample_id", reps))
  y = y %>% order_feature()
  list(no=bin.no, x=y, map=feature.bin);
}

#### read function abs
#### functions, c("cog", "kog", "pfam", "tigrfam", "KO", "EC") 
#### cutoff, function id will be kept as long as one sample have this function at least cutoff
#### order_fun, order function ids decreasingly, can be sum or max 
read_kegg_tibble <- function(dir, functions=c("AMR-KO", "EC-KO", "module-KO", "module",
                                              "pathway-KO", "pathway", "transporter-KO"), 
                             cutoff=0.01) {
  col_start = list();
  col_start[["AMR-KO"]]  = 8;
  col_start[["EC-KO"]]   = 8;
  col_start[["module-KO"]] = 9;
  col_start[["module"]] = 6;
  col_start[["pathway-KO"]]  = 8;
  col_start[["pathway"]]   = 5;
  col_start[["transporter-KO"]] = 8;

  col_key = list();
  col_key[["AMR-KO"]]  = 6;
  col_key[["EC-KO"]]   = 6;
  col_key[["module-KO"]] = 7;
  col_key[["module"]] = 1;
  col_key[["pathway-KO"]]  = 6;
  col_key[["pathway"]]   = 1;
  col_key[["transporter-KO"]] = 6;

  fun_list=list();
  for (tf in functions) {
    df   = read_tsv(paste(dir, paste(tf, "-R.depth-adjusted.tsv", sep=""), sep="/"))
    colnames(df)[ col_key[[tf]] ] = "name"
    if (tf %in% c("pathway-KO", "module-KO")) {
      df = df %>% mutate(name = paste(ko, name, sep=".") )
    }
    df = df %>% group_by(name) %>% filter(row_number() == 1) %>% ungroup()

    cols = colnames(df)
    i1   = col_start[[tf]]
    i2   = length(cols)
    samples = cols[ i1:i2 ]

    feature = df %>% dplyr::select(1:(i1-1)) %>%
      mutate(max = as.vector( apply(df[, i1:i2], 1, max       ))) %>%
      mutate(mean = as.vector( apply(df[, i1:i2], 1, mean       )))

    abs = as_tibble(t(df %>% dplyr::select(i1:i2)))
    colnames(abs) = feature$name
    abs = abs %>% mutate(sample_id = samples) %>% dplyr::select(c("sample_id", df$name))

    #### filter cutoff
    feature = feature %>% filter(max >= cutoff)
    abs = abs %>% dplyr::select(c("sample_id", feature$name))
    fun_list[[tf]]=abs
    fun_list[[paste(tf,"_info",sep="")]] = feature
  }
  fun_list;
}


#### read humann2 function abs (unit CPM)
#### cutoff, function id will be kept as long as one sample have this function at least cutoff
#### order_fun, order function ids decreasingly, can be sum or max 
read_humann2_function_tibble <- function(dir, functions=c("ko", "ec", "go", "rxn", "metacyc"), cutoff=1) {

  fun_list=list();
  for (tf in functions) {
    df   = read_tsv(paste(dir, paste(tf, ".tsv", sep=""), sep="/"))
    colnames(df)[ 1 ] = "name"
    df = df %>% group_by(name) %>% filter(row_number() == 1) %>% ungroup()

    cols = colnames(df)
    i1   = 3
    i2   = length(cols)
    samples = cols[ i1:i2 ]

    feature = df %>% dplyr::select(1:(i1-1)) %>%
      mutate(max = as.vector( apply(df[, i1:i2], 1, max       ))) %>%
      mutate(mean = as.vector( apply(df[, i1:i2], 1, mean       )))

    abs = as_tibble(t(df %>% dplyr::select(i1:i2)))
    colnames(abs) = feature$name
    abs = abs %>% mutate(sample_id = samples) %>% dplyr::select(c("sample_id", df$name))

    #### filter cutoff
    feature = feature %>% filter(max >= cutoff)
    abs = abs %>% dplyr::select(c("sample_id", feature$name))
    fun_list[[tf]]=abs
    fun_list[[paste(tf,"_info",sep="")]] = feature
  }
  fun_list;
}


#### calculate Shannon index and species richness, please use other
#### filter function to remove low abundance, rare features, e.g.
####   reduce_taxon_tib, reduce_zero_feature, reduce_rare_feature
#### x sample_feature table
#### also Pielou's evenness = Shannon / Shannon_max
#### Shannon_max is the maximum possible Shannon, when all species have the same abundance 
sample_div <- function(x, cutoff = 0) {
  divf1 <- function(x) { sum(x > cutoff) }
  divf1a <- function(x) {
    y = x[ x> cutoff]
    y = y/sum(y) #### re norm to 1.0000
    -1 * sum(y*log(y))
  }

  x %>% dplyr::select(1) %>% 
      mutate(richness = as.vector(apply(x %>% dplyr::select(-1), 1, divf1 )),
             shannon  = as.vector(apply(x %>% dplyr::select(-1), 1, divf1a))) %>%
      mutate(evenness = shannon / log(richness))
}


#### input a metadata tibble
#### columns are metadata features
#### this function filters out columns with too many NAs
#### return a filtered tibble
metadata_tib_filter_NA_features <- function(x, cutoff = 0.5) {
  cutoff_n = nrow(x) * cutoff
  y = tibble(name = colnames(x), notNA = x %>% apply(2, function(x){ sum(as.integer(!is.na(x)))}))
  y = y %>% filter(notNA >= cutoff_n)
  x %>% dplyr::select(y$name)
}

#### input a metadata tibble
#### columns are metadata features
#### this function filters out columns with almost identical data
#### if a column has only two values (e.g. Yes/No or 1/0), and if one value is less than 5% in samples
####      this column is not really useful
#### return a filtered tibble
metadata_tib_filter_uneven_binary_features <- function(x, cutoff = 0.05) {
  cutoff_n = nrow(x) * cutoff

  f1 <- function(x) {
    x1 = x[!is.na(x)]
    len = length(unique(x1))
    if (len > 2) { #### > 2 values
      return("even")
    }
    if (len < 2) { #### only 0 or 1 value
      return("uneven")
    }
    keys = unique(x1)
    no1 = sum( x1 %in% keys[1])
    no2 = sum( x1 %in% keys[2])
    if (no1 < cutoff_n) {
      return("uneven")
    }
    else if (no2 < cutoff_n) {
      return("uneven")
    }
    else {
      return("even")
    }
  }

  y = tibble(name = colnames(x), good_feature = x %>% apply(2, f1))
  y = y %>% filter(good_feature == "even")
  x %>% dplyr::select(y$name)
}


#### serving the next few functions
#### permutation_multi_group
#### permutation_two_group
#### permutation_two_group_prop
adj_func <- function(this.p, dist, n_test) {
  if (is.na(this.p)) return(1)
  this.adj.p = (1+sum( this.p >= dist)) / (1+length(dist))
  if ((this.p * n_test) < this.adj.p) {
    this.adj.p = this.p * n_test
  }
  this.adj.p
}
#### x feature table
####     1st column must be sample, 
####     2nd column must be group, as factor
####     other cols are features
#### use Kruskal-Wallis Rank Sum Test to find significant features between groups
#### multiple test correction by permutating groups, see
####     Sham, Pak C., and Shaun M. Purcell. "Statistical power and significance testing in large-scale genetic studies." 
####     Nature Reviews Genetics 15.5 (2014): 335.
#### g_case / g_control: vector of names of case or control
#### n: number simulation, 
permutation_multi_group <- function (x, n=1000, rand.seed=42, my.test=kruskal.test) {
  features = colnames(x)[3:ncol(x)]
  num_samples = nrow(x)
  colnames(x)[2] = "GROUP"
  x = x %>% mutate(GROUP = as.factor(GROUP))
  grp = x$GROUP

  set.seed(rand.seed)
  dist.p = numeric(0); #### minmal p distribution
  for (test_run in 1:n) {
    zp1.func     = function (v)      {z1=my.test(x[[v]], sample(grp) ); z1$p.value;}
    zlist = as.vector(sapply(features, FUN=zp1.func))
    zp.min = min(c(1, zlist[!is.na(zlist)]))
    dist.p=c(dist.p, zp.min);
  }
  dist.p =  dist.p[order(dist.p)];

  zp1.func     = function (v)      {z1=my.test(x[[v]], grp); z1$p.value;}
  raw.p = as.vector(sapply(features, FUN=zp1.func))
  p = tibble(name=features, raw.p=raw.p, adjust.p = sapply(raw.p, function(x) {adj_func(x, dist.p, length(features))} ))
  p %>% arrange( adjust.p)
}

#### similar to permutation_two_group2, but have three groups
permutation_three_group <- function (x, group, n=1000, rand.seed=42, my.test=wilcox.test, adjust.method="permutation", paired=F) {
  n1 = ncol(x)-1
  colnames(group)[2] = "GROUP"
  g1 = (x %>% dplyr::select(1) %>% inner_join(group))$GROUP
  g2 = sort(unique(g1))

  if (length(g2) != 3) return(NULL)
  sig = list()
  for (i in 1:2) {
    gr.A = g2[i]
    for (j in (i+1):3) {
      gr.B = g2[j]
      t.g = group %>% filter(GROUP %in% c(gr.A, gr.B))
      t.x = x %>% inner_join(t.g %>% dplyr::select(1))
      t.sig = permutation_two_group2(t.x, t.g, n, rand.seed, my.test, adjust.method, paired=paired) %>% dplyr::select(1, 2, 3, 6) #### un select means
      ij = paste(i,j,sep=".")
      colnames(t.sig) = c("name", paste("raw.p", ij, sep="_"), paste("adjust.p", ij, sep="_"), paste("LOG10_FC", ij, sep="_"))
      sig[[paste("p",ij,sep="")]] = t.sig
    }
  }
  p = tibble(name=colnames(x)[-1]) %>% 
    inner_join(sig$p1.2) %>% inner_join(sig$p1.3) %>% inner_join(sig$p2.3) %>%
    mutate(m1 = as.vector(apply(x %>% inner_join(group %>% filter(GROUP == g2[1]) %>% dplyr::select(1)) %>% dplyr::select(-1) , 2, mean)),
           m2 = as.vector(apply(x %>% inner_join(group %>% filter(GROUP == g2[2]) %>% dplyr::select(1)) %>% dplyr::select(-1) , 2, mean)),
           m3 = as.vector(apply(x %>% inner_join(group %>% filter(GROUP == g2[3]) %>% dplyr::select(1)) %>% dplyr::select(-1) , 2, mean)),
           adjust.p.min = pmin(adjust.p_1.2, adjust.p_1.3, adjust.p_2.3),
           raw.p.min    = pmin(   raw.p_1.2,    raw.p_1.3,    raw.p_2.3) )

  colnames(p)[11] = paste("mean", g2[1], sep=".")
  colnames(p)[12] = paste("mean", g2[2], sep=".")
  colnames(p)[13] = paste("mean", g2[3], sep=".")
  p %>% dplyr::select(1, 15, 14, 11, 12, 13, 2:10) %>% arrange(adjust.p.min)
}

######## permutation_two_group2 is shorter than the permutation_two_group
#### x feature table
#### use wilcox.test or t test to find significant features between two groups
#### multiple test correction by permutating groups, see
####     Sham, Pak C., and Shaun M. Purcell. "Statistical power and significance testing in large-scale genetic studies." 
####     Nature Reviews Genetics 15.5 (2014): 335.
#### group 
#### n: number simulation, 
permutation_two_group2 <- function (x, group, n=1000, rand.seed=42, my.test=wilcox.test, adjust.method="permutation", paired=F) {
  n1 = ncol(x)-1
  colnames(group)[2] = "GROUP"
  g1 = (x %>% dplyr::select(1) %>% inner_join(group))$GROUP 
  g2 = sort(unique(g1))

  if (adjust.method == "permutation") {
    set.seed(rand.seed)
    dist.p = numeric(0); #### minmal p distribution
    for (test_run in 1:n) {
      zlist = as.vector( sapply( x %>% dplyr::select(-1), function(i) my.test(i ~ sample(g1), paired=paired)$p.value) )
      zp.min = min(c(1, zlist[!is.na(zlist)]))
      dist.p=c(dist.p, zp.min);
    }
    dist.p =  dist.p[order(dist.p)];
  }
  
  # for real case vs control
  raw.p = as.vector(sapply( x %>% dplyr::select(-1), function(i) my.test(i ~ g1, paired=paired)$p.value) )
  if (adjust.method == "permutation") {
    p.adj = sapply(raw.p, function(x) {adj_func(x, dist.p, n1)} )
  } 
  else {
    p.adj = p.adjust(raw.p, method=adjust.method)
  }

  p = tibble(name     = colnames(x)[-1],
             raw.p    = raw.p,
             adjust.p = p.adj,
             mean.g1  = as.vector(apply(x %>% inner_join(group %>% filter(GROUP == g2[1]) %>% dplyr::select(1)) %>% dplyr::select(-1) , 2, mean)),
             mean.g2  = as.vector(apply(x %>% inner_join(group %>% filter(GROUP == g2[2]) %>% dplyr::select(1)) %>% dplyr::select(-1) , 2, mean)))

  mm = x %>% dplyr::select(-1) %>% as.matrix() #### global min / 2
  v.min = min( mm[mm>0] ) / 2;
  p = p %>% mutate( log10.fc = log10((mean.g1+v.min)/(mean.g2+v.min) ) ) %>% arrange( adjust.p)
  colnames(p)[4] = paste("mean", g2[1], sep=".")
  colnames(p)[5] = paste("mean", g2[2], sep=".")
  p
}

#### x feature table
#### use wilcox.test or t test to find significant features between two groups
#### multiple test correction by permutating groups, see
####     Sham, Pak C., and Shaun M. Purcell. "Statistical power and significance testing in large-scale genetic studies." 
####     Nature Reviews Genetics 15.5 (2014): 335.
#### g_case / g_control: vector of names of case or control
#### n: number simulation, 
permutation_two_group <- function (x, g_case, g_control, n=1000, rand.seed=42, my.test=wilcox.test, paired=F,
                                   mean.names=c("mean.case","mean.control")) {
  features = colnames(x)[-1]
  num_samples = nrow(x)
  num_case    = length(g_case)
  num_control = length(g_control)

  set.seed(rand.seed)
  dist.p = numeric(0); #### minmal p distribution
  for (test_run in 1:n) {
    t_all     = sample(1:num_samples)
    t_case    = t_all[           1:num_case]
    t_control = t_all[(num_case+1):num_samples]

    zp1.func     = function (v)      {z1=my.test(x[[v]][t_case], x[[v]][t_control], paired=paired); z1$p.value;}
    zlist = as.vector(sapply(features, FUN=zp1.func))
    zp.min = min(c(1, zlist[!is.na(zlist)]))
    dist.p=c(dist.p, zp.min);
  }
  dist.p =  dist.p[order(dist.p)];

  # for real case vs control
  colnames(x)[1] = "UUID"
  data.case    = x %>% filter(UUID %in% g_case)
  data.control = x %>% filter(UUID %in% g_control)
  zp1.func     = function (v)      {z1=my.test(data.case[[v]], data.control[[v]], paired=paired); z1$p.value;}
  raw.p = as.vector(sapply(features, FUN=zp1.func))

  p = tibble(name        = features, 
             raw.p       = raw.p, 
             adjust.p    = sapply(raw.p, function(x) {adj_func(x, dist.p, length(features))} ),
             mean.case   = as.vector(apply(data.case    %>% dplyr::select(-UUID), 2, mean)),
             mean.control= as.vector(apply(data.control %>% dplyr::select(-UUID), 2, mean)) )
  v.min = min(c(p$mean.case, p$mean.control)) / 2;
  p = p %>% mutate( fc = (mean.case+v.min)/(mean.control+v.min)) %>% arrange( adjust.p)
  colnames(p)[4] = mean.names[1];
  colnames(p)[5] = mean.names[2];
  p
}



#### x feature table
#### use prop.test to find significant features between two groups
#### multiple test correction by permutating groups, see
####     Sham, Pak C., and Shaun M. Purcell. "Statistical power and significance testing in large-scale genetic studies." 
####     Nature Reviews Genetics 15.5 (2014): 335.
#### g_case / g_control: vector of names of case or control
#### n: number simulation, 
permutation_two_group_prop <- function (x, g_case, g_control, n=1000, rand.seed=42, cutoff = 0, my.test=prop.test,
                                        mean.names=c("prop.case","prop.control")) {
  features = colnames(x)[-1]
  num_samples = nrow(x)
  num_case    = length(g_case)
  num_control = length(g_control)
  y = c(num_case, num_control)

  x1 = as_tibble((x %>% dplyr::select(-1)) > cutoff) #### convert to T / F
  x1 = bind_cols(x %>% dplyr::select(1),  x1)

  set.seed(rand.seed)
  dist.p = numeric(0); #### minmal p distribution
  for (test_run in 1:n) {
    t_all     = sample(1:num_samples)
    t_case    = t_all[           1:num_case]
    t_control = t_all[(num_case+1):num_samples]

    zp1.func     = function (v)      {z1=my.test(c(sum(x1[[v]][t_case]), sum(x1[[v]][t_control])), y); z1$p.value;}
    zlist = as.vector(sapply(features, FUN=zp1.func))
    zp.min = min(c(1, zlist[!is.na(zlist)]))
    dist.p=c(dist.p, zp.min);
  }
  dist.p =  dist.p[order(dist.p)];

  # for real case vs control
  colnames(x1)[1] = "UUID"
  data.case    = x1 %>% filter(UUID %in% g_case)
  data.control = x1 %>% filter(UUID %in% g_control)
  zp1.func     = function (v)      {z1=my.test(c(sum(data.case[[v]]), sum(data.control[[v]])), y); z1$p.value;}
  raw.p = as.vector(sapply(features, FUN=zp1.func))

  p = tibble(name        = features, 
             raw.p       = raw.p,
             adjust.p    = sapply(raw.p, function(x) {adj_func(x, dist.p, length(features))} ),
             prop.case   = as.vector(apply(data.case    %>% dplyr::select(-UUID), 2, sum)) / num_case,
             prop.control= as.vector(apply(data.control %>% dplyr::select(-UUID), 2, sum)) / num_control)
  colnames(p)[4] = mean.names[1];
  colnames(p)[5] = mean.names[2];
  p %>% arrange( adjust.p)
}

#### pairwise testing
#### x long format tibble
#### first column group
#### second column value
pairwise_multi_group_test <- function(x, my.test=wilcox.test) {
  colnames(x)[1] = "group"
  colnames(x)[2] = "value"
  x = x %>% mutate(group = as.factor(group))
  gr = levels(x$group)
  len = length(gr)

  g1lab = character(0)
  g2lab = character(0)
  p = numeric(0)

  for (i in 1:(len-1)) {
    g1 = gr[i]
    v1 = (x %>% filter(group == g1))$value
    for (j in (i+1):len) {
      g2 = gr[j]
      v2 = (x %>% filter(group == g2))$value
      zp = my.test(v1, v2)
      if (! is.na(zp$p.value)) {
        g1lab = c(g1lab, g1)
        g2lab = c(g2lab, g2)
        p     = c(p, zp$p.value)
      }
    }
  }
  tibble(group1 = g1lab, group2=g2lab, p.value=p) %>% arrange(p.value)
}


#### call next function, alow multiple cutoffs
df_2_rarefaction_m <- function (x, cutoffs, num_sampling=10, step=1, rand.seed=42) {
  num_rows = dim(x)[1];
  steps = seq.int(step, num_rows, step);

  out.mat = matrix(0, nrow=length(steps), ncol = 1+length(cutoffs));
  out.mat[, 1] = steps;
  for (i in 1:length(cutoffs)) {
    cutoff = cutoffs[i];
    out.mat[, i+1] = df_2_rarefaction(x, cutoff, num_sampling, step, rand.seed);
  }
  rownames(out.mat) = steps;
  colnames(out.mat) = c("Number_samples", paste("cutoff", cutoffs, sep=""));
  as.data.frame(out.mat);
}

#### given a taxon df 
#### calculate rarefaction curve
df_2_rarefaction <- function (x, cutoff = 0.0001, num_sampling=10, step=1, rand.seed=42) {
  num_rows = dim(x)[1];
  num_cols = dim(x)[2];
  set.seed(rand.seed);
  steps = seq.int(step, num_rows, step);

  for (i in 1:num_sampling) {
    df1 = x[sample(1:num_rows), ];
    v = numeric(0);
    j_last = 1;
    for (j in steps) {
      t_max = as.vector(apply(df1[j_last:j, 1:num_cols, drop=F], 2, max));
      v = c(v, sum(t_max >= cutoff));
      df1[j, ] = t_max; #### assign j_last to j's max to current j, so that next iteration won't need last block
      j_last = j;
    }

    if (i == 1) { 
      df.out = data.frame(steps=steps, v=v);
      rownames(df.out) = steps;
    }
    else {
      df.out = data.frame(df.out, v=v);
    }
  }

  df.out=df.out[, 2:(num_sampling+1)];
  sort(apply(df.out, 1, mean));
}

#### transpose
#### first column name
tibble_t <- function(x, key.name="name") {
  x.col = colnames(x)[-1]
  colnames(x)[1] = "UUID"
  x.row = x$UUID

  y = x %>% dplyr::select(-1) %>% t() %>% as_tibble()
  y = tibble(name = x.col) %>% inner_join(y %>% mutate(name = x.col))
  colnames(y) = c(key.name, x.row)
  y
}

#### tibble to data.frame, use first column of input as rownames of df
#### col_for_row_name, use this column as the rowname for output df
tibble_2_df <- function(x, col_for_row_name = NULL) {
  if (is.null(col_for_row_name) ) col_for_row_name = colnames(x)[1]
  new.rownames = x[[col_for_row_name]]
  y = x %>% dplyr::select(-all_of(col_for_row_name)) %>% as.data.frame()
  rownames(y) = new.rownames
  y
}

#### given a ggplot object
#### return only the legend part of the plot
#### so this can be used in a panel of multi figures
grep_gplot_legend<-function(x.plot) {
  y = ggplot_gtable(ggplot_build(x.plot))
  leg = which(sapply(y$grobs, function(x) x$name) == "guide-box")
  y$grobs[[leg]]
}

#### Random Forest
#### y: target tibble, 1st column is sample, 2nd column is factor of (Disease, Normal)
#### x: feature tibble, 1st column is sample
#### x1: other metadata tibble (demographic, age, sex), 1st column 1 is sample
#### split: split data into n partitions, n-1 as training, 1 as validation 
rf.test <- function(y, x, x1, disease_class = "Disease", topN_feature=30, rf.ntree=500, rf.mtry=30, split=2) {
  df = y %>% inner_join(x1) %>% inner_join(x) %>% dplyr::select(-1) %>% as.data.frame()

  if (topN_feature > ncol(df)-1) {
    topN_feature = ncol(df)-1
  }
  target.name = colnames(y)[2]
  colnames(df)[1] = "TARGET"
  set.seed(42)

  sample.t = sample(2, nrow(df), replace=T, prob=c((split-1)/split, 1/split))
  df.dev=df[sample.t==1,]
  df.val=df[sample.t==2,]
  table(df$TARGET    ) / nrow(df)
  table(df.dev$TARGET) / nrow(df.dev)
  table(df.val$TARGET) / nrow(df.val)

  set.seed(42)
  cutoff1 = nrow(filter(df.dev, TARGET == disease_class)) / nrow(df.dev)
  df.rf = randomForest(formula = TARGET~., data=df.dev, ntree=rf.mtry, importance=T, proximity=T, mtry=rf.mtry, cutoff=c(cutoff1, 1-cutoff1));
  df.features = importance(df.rf)
  df.features = as_tibble(df.features) %>% mutate(feature = rownames(df.features)) %>% arrange(-MeanDecreaseGini)

  pred_f <- function(fit, x) { predict(fit, x, type="prob")[,2] }
  pred <- prediction(pred_f(df.rf, df.val), as.numeric(df.val[,"TARGET"]))
  perf <- performance(pred, "tpr", "fpr" )
  AUC  <- performance(pred,"auc")@y.values[[1]]
  plot_AUC = ggplot(data.frame(x=perf@x.values[[1]], y=perf@y.values[[1]]), aes(x=x, y=y)) + geom_line() +
     labs(x="False positive", y="True positive", subtitle="ROC") +
     annotate("text", label=paste("AUC = ",format(AUC, digits=5, scientific=FALSE)), x=0.5, y=0.5)

  z= df.val[, as.vector(unlist( df.features[1:topN_feature,5])) ]
  z= as_tibble(apply(z, 2, rank)) %>% mutate(TARGET = df.val$TARGET)
  plot1 = ggplot(melt(z), aes(x=variable, y=value, colour=TARGET)) + geom_boxplot()+
    labs(x="Feature", y="Rank") + theme(axis.text.x=element_text(angle=90))+
    guides(colour = guide_legend(title=target.name))

  z= df.val[, as.vector(unlist( df.features[1:topN_feature,5])) ]  %>% mutate(TARGET = df.val$TARGET)
  plot2 = ggplot(melt(z), aes(x=variable, y=value, colour=TARGET)) + geom_boxplot()+
    labs(x="Feature", y="") + theme(axis.text.x=element_text(angle=90))+
    guides(colour = guide_legend(title=target.name))
  list(rf=df.rf, features=df.features, auc=AUC, plot.auc=plot_AUC, plot.f=plot1, plot.f1=plot2)
}


#### make hclust opject for species or genus
taxonomy_2_hclust <- function(x, d.max=0.8) {
  colnames(x)[1] = 'TARGET'
  org = x$TARGET
  col.names = colnames(x)

  dist1 = list()
  dist1[['superkingdom']] = 0.7
  dist1[['phylum']] = 0.6
  dist1[['class']] = 0.5
  dist1[['order']] = 0.4
  dist1[['family']] = 0.3
  dist1[['genus']] = 0.2
  dist1[['species']] = 0.1
  dist1[['toprank']] = 0.0

  n.org = nrow(x)
  d.mat=matrix(ncol=n.org, nrow=n.org)

  for (i in 1:n.org) {
    d.mat[i,i] = 0
    for (j in (i+1):n.org) {
      if (j>n.org) {
        next
      }
      d = d.max 
      for (k in ncol(x):2) {
        if (x[i, k] == 'NULL') {
          next
        }
        if (x[j, k] == 'NULL') {
          next
        }
        if (x[i, k] == x[j, k]) {
          d = dist1[[col.names[k]]]
          break
        }
      }
      d.mat[i,j] = d
      d.mat[j,i] = d
    }
  }
  colnames(d.mat) = org
  rownames(d.mat) = org
  hr = hclust(as.dist(d.mat), method="single")
  hr
}

#### more general case to produce a hclust object
#### for kegg and other features
#### e.g. feature_2_hclust(x)
#### here x is tibble
#### name	super_pathway	sub_pathway
#### kegg1      super_pathwayA	sub_pathwayX
#### kegg1      super_pathwayA	sub_pathwayY
#### kegg1      super_pathwayA	sub_pathwayX
feature_2_hclust <- function(x) {
  colnames(x)[1] = 'TARGET'
  org = x$TARGET
  col.names = colnames(x)
  n.desc = ncol(x)-1
  d.step = 1 / (n.desc+2)
  d.max = 1 - d.step

  n.org = nrow(x)
  d.mat=matrix(ncol=n.org, nrow=n.org)
  for (i in 1:n.org) {
    d.mat[i,i] = 0
    for (j in (i+1):n.org) {
      if (j>n.org) {
        next
      }
      d = d.max
      for (k in ncol(x):2) {
        if (x[i, k] == x[j, k]) {
          d = d.step * (n.desc + 2 - k)
          break
        }
      }
      d.mat[i,j] = d
      d.mat[j,i] = d
    }
  }
  colnames(d.mat) = org
  rownames(d.mat) = org
  hclust(as.dist(d.mat), method="single")
}


#### dist to cluster
#### input dist matrix tibble
#### first row name
#### return tibble cols: name, bin, rep, dist to rep
#### pre_seed, can be vector of a list of pre-selected representatives
#### pre_order, tibble, first column is name, ordered, so that front are selected as seeds
dist_2_cluster <- function(x, cutoff.d = NA, cutoff.k = NA, pre_seed=NULL, pre_order=NULL) {
  features = colnames(x)[-1]
  x.mat = as.matrix(x %>% dplyr::select(-1))
  rownames(x.mat) = features
  hr = hclust(as.dist(x.mat))

  if (! is.na(cutoff.k)) {
    hr.cut = cutree(hr, k = cutoff.k)
  } else if (! is.na(cutoff.d)) {
    hr.cut = cutree(hr, h = cutoff.d)
  } else {
    hr.cut = cutree(hr, h = 0)
  }

  x.bin = tibble(name = names(hr.cut), bin = hr.cut) %>% arrange(bin)
  x.mat = x.mat[x.bin$name, x.bin$name] #### re order


  x.clstr_rep = tibble(bin = 1:max(x.bin$bin)) #### don't join
  x.clstr_rep = x.clstr_rep %>%
    mutate(rep = sapply(1:max(x.bin$bin), function(x) { names(sort(apply(x.mat[ x.bin$bin==x, x.bin$bin==x, drop=F], 1, sum))[1]) } ))

  if (! is.null(pre_seed)) { #### pre-selected seed
    pre = x.bin %>% filter(name %in% pre_seed) %>% group_by(bin) %>% filter(row_number()==1) %>% ungroup() %>% 
        mutate(rep=name) %>% dplyr::select(bin, rep)
    x.clstr_rep = pre %>% rbind(x.clstr_rep) %>% group_by(bin) %>% filter(row_number()==1) %>% ungroup()
  }

  if (! is.null(pre_order)) {
    colnames(pre_order)[1] = "name"
    x.clstr_rep = pre_order %>% dplyr::select(1) %>% inner_join(x.bin) %>%
      group_by(bin) %>% filter(row_number()==1) %>% ungroup() %>% 
      mutate(rep=name) %>% dplyr::select(bin, rep)
  }

  x.bin = x.bin %>% inner_join(x.clstr_rep) #### don't join
  x.bin = x.bin %>%
    mutate(dist = sapply(row_number(), function(x){ x.mat[ x.bin$name[x],x.bin$rep[x]]}))
  x.bin
}

#### similar to dist_2_cluster, but use greedy incremental method
#### so requires pre-ordering, the one on top are first selected as seed
#### dist to cluster
#### input dist matrix tibble
#### first row name
#### return tibble cols: name, bin, rep, dist to rep
#### pre_order, tibble, first column is name, ordered, so that front are selected as seeds
#### support 
dist_2_cluster_greedy <- function(x, cutoff.d, pre_order, pre_cutoff) {
  colnames(x)[1] = "UUID";
  colnames(pre_order)[1] = "UUID";
  x = pre_order %>% inner_join(x, by=c("UUID" = "UUID"))
  features = x$UUID;
  x = x %>% select(c("UUID", features))
  x.mat = as.matrix(x %>% dplyr::select(-1))
  rownames(x.mat) = features
  N = length(features)
  #### now mat is reordered by 

  if (! is.null(pre_cutoff)) {
    colnames(pre_cutoff)[1] = "UUID"
    colnames(pre_cutoff)[2] = "cutoff"
    cutoffs = (x %>% left_join(pre_cutoff) %>% replace_na(list(cutoff=0)))$cutoff #### left join, so same length as x
  }
  else {
    cutoffs = rep(cutoff.d, N)
  }
  
  #### clustering
  rep.bin = list()
  rep.idx = c(1)
  no.bin = 1
  x.bin = tibble(name=features[1], bin=no.bin, rep=features[1], dist=0) #### first one become first seed
  rep.bin[[features[1]]] = no.bin
  no.bin = no.bin +1

  for (i in 2:N) {
    tcutoff = cutoffs[i]
    min.d = min(x.mat[i, rep.idx])
    if ( min.d <= tcutoff) { #### clustered
      rep.i = rep.idx[ min.d == x.mat[i, rep.idx]] #### may be array
      rep.i = rep.i[1] ### may ba array, use 1st one
      rep.name = features[rep.i] 
      x.bin = x.bin %>% rbind(tibble(name=features[i], bin=rep.bin[[rep.name]], rep=rep.name, dist=min.d))
    }
    else { #### new seed
      x.bin = x.bin %>% rbind(tibble(name=features[i], bin=no.bin, rep=features[i], dist=0))
      rep.bin[[features[i]]] = no.bin
      rep.idx = c(rep.idx, i)
      no.bin = no.bin +1
    }
  }
  x.bin %>% arrange(bin, dist)
}


#### save a pheatmap object to a file
#### x = pheatmap(...)
#### 
save_pheatmap_png <- function(x, filename, width, height, pointsize=12 ) {
  png(filename, width=width, height=height, pointsize=pointsize)
  grid::grid.newpage()
  grid::grid.draw(x$gtable)
  dev.off()
}

save_pheatmap_tiff <- function(x, filename, width, height, pointsize=12 ) {
  tiff(filename, width=width, height=height, pointsize=pointsize)
  grid::grid.newpage()
  grid::grid.draw(x$gtable)
  dev.off()
}

save_ggplot_png <- function(x, filename, width, height, pointsize=12 ) {
  png(filename, width=width, height=height, pointsize=pointsize)
  print(x)
  dev.off()
}

save_ggplot_tiff <- function(x, filename, width, height, pointsize=12 ) {
  png(filename, width=width, height=height, pointsize=pointsize)
  print(x)
  dev.off()
}


#### bind two feature tibbles, x and y, which may have different set of features
#### both x and y are tibbles
#### first column is sample_id
tibble_bind_rows <- function(x, y, fill=0) {
  z = bind_rows(x, y)
  features = colnames(z)[-1]
  for (i in features) {
    z[[i]] = z[[i]] %>% replace_na(fill)
  }
  z
}


#### x sample-feature tibble
#### p.adjusti.method = c("holm", "hochberg", "hommel", "bonferroni", "BH", "BY", "fdr", "none")
#### method = c("pearson", "kendall", "spearman")
co.network.ez <- function(x, method="spearman", p.cutoff = 0.05, p.adjust.methods="BH") {
  n_feature = ncol(x)-1
  test1 = corr.test(x %>% select(-1), method=method, adjust=p.adjust.methods)
  p.t = test1$p %>% t()
  pair = combn(colnames(x)[-1], 2) 
  pair_info = tibble(feature1 = pair[1,] %>% as.vector(), #### making pairwise 
                     feature2 = pair[2,] %>% as.vector(),
                     d        = test1$r[ lower.tri( test1$r,   diag=F)],   #### mat[lower.tri(mat)] -> output vector from left -> right
                     p        = test1$p[ lower.tri( test1$p,   diag=F)],  
                     p.adj    =     p.t[ lower.tri( p.t,       diag=F)])
  pair_info = pair_info %>% mutate(edge = p.adj <= p.cutoff)

  ## to copy upper to lower triangle try this
  ## mat.t = mat %>% t()
  ## mat[lower.tri(mat)] = mat.t[lower.tri(mat.t)]
  adj.mat = test1$p
  adj.mat[                  ] = 1
  adj.mat[ p.mat > p.cutoff ] = 0
  adj.mat[ lower.tri(adj.mat, diag = T) ] = 0

  g1 = graph.adjacency(adj.mat, mode = "upper", weighted = TRUE, diag = F)
  #### Finding community structure by multi-level optimization of modularity
  g1.cls = cluster_louvain(g1)
  g1.t = tibble(name   = g1.cls$name, idx = 1:n_feature, clstr = g1.cls$membership, degree = igraph::degree(g1))
  g1.cls.bin = g1.t %>% group_by(clstr) %>% summarise(binsize=length(name)) %>%
    arrange(desc(binsize)) %>% mutate(clstr_sorted = 1:max(g1.t$clstr))
  g1.t = g1.t %>% inner_join(g1.cls.bin)
  
  list(test=test1, adj.mat=adj.mat, graph=g1, gr=g1.t, pair=pair_info)
}


######## pathway, network, graph etc
#### build co-occuring network based for two omic data types
####   e.g. microbiome vs host RNAseq
#### x, y are input omic tables
#### method: correlation method, e.g. pearson or spearman
#### p.cutoff: p.value cutoff, edges with p.value above this cutoff will be ignored
#### rm.negative: ignore negative correlation
co.network.two.omic.types <- function(x, y, names=c("omic.A", "omic.B"), 
    method="pearson", p.cutoff = 0.05, rm.negative = F) {

  df.join = x %>% inner_join(y)
  d.cor = cor(df.join %>% select(-1), method=method)
  if (rm.negative) { #### remove negative correlation
    d.cor[ d.cor <0 ] = 0;
  }

  p.cor = corr.p(d.cor, nrow(df.join))$p #### only with lower triangle
  #### uppper is adjusted , now using un-adjusted p value
  #### so re-assign to 1 for upper
  p.cor[upper.tri(p.cor)] = 1

  p.pair = gather(p.cor %>% as_tibble %>% mutate(from=rownames(p.cor)), key="to", value="p.value", -from) %>%
           filter( p.value <= p.cutoff) %>% filter( ! from == to)
  r.pair = gather(d.cor %>% as_tibble %>% mutate(from=rownames(d.cor)), key="to", value="r",       -from) #### raw r
  p.pair = p.pair %>% inner_join(r.pair)
  p.pair = p.pair %>% 
           mutate( from_c = names[as.integer(from %in% colnames(y))+1]) %>%
           mutate( to_c   = names[as.integer(to   %in% colnames(y))+1]) %>%
           mutate( class  = c("cross","internal")[as.integer(to_c == from_c)+1])

  p.cor = Matrix::forceSymmetric(p.cor, "L") #### copy lower triangle to uppper
  p.cor = as.matrix(p.cor)
  p.cor[ p.cor == 0       ] = min(p.cor[p.cor!=0])/10 #### assign min(p ij)/10 => pii
  p.cor[ p.cor > p.cutoff ] = 1
  d.cor[ p.cor > p.cutoff ] = 0
  p.log = -log10(p.cor)
  diag(p.log) = 0 

  g1 = graph.adjacency(p.log, mode = "undirected", weighted = TRUE, diag = T)
  #### Finding community structure by multi-level optimization of modularity
  g1.cls = cluster_louvain(g1)
  g1.t = tibble(name   = g1.cls$name, 
                idx    = 1:nrow(p.log), 
                clstr  = g1.cls$membership, 
                degree = degree(g1),
                group = c(rep(names[1], ncol(x)-1), rep(names[2], ncol(y)-1)),
                shape = c(rep("square", ncol(x)-1), rep("circle", ncol(y)-1)))

  g1.cls.bin = g1.t %>% group_by(clstr) %>% 
               summarise(binsize=length(name), class=c("internal","cross")[length(unique(group))]) %>%
               arrange(desc(binsize)) %>% mutate(clstr_sorted = 1:max(g1.t$clstr))

  g1.t = g1.t %>% inner_join(g1.cls.bin)

  #### making a edge color mat
  e.col = matrix("white", ncol=nrow(g1.t), nrow=nrow(g1.t))
  for (i in 1:(nrow(g1.t)-1)) {
    for (j in (i+1):nrow(g1.t)) {
      z1 = (g1.t %>% filter(idx %in% c(i,j)))$group
      if (z1[1] != z1[2]) {
        tc="red"
      } else if (z1[1] == names[1]) {
        tc="green"
      } else {
        tc="yellow"
      }
      e.col[i,j] = tc
      e.col[j,i] = tc
    }
  }
  p.pair = p.pair %>% inner_join(g1.t %>% select(name, clstr_sorted) %>% mutate(clstr_from=clstr_sorted) %>% select(-clstr_sorted), 
                                 by=c("from" = "name") ) %>% 
                      inner_join(g1.t %>% select(name, clstr_sorted) %>% mutate(clstr_to  =clstr_sorted) %>% select(-clstr_sorted), 
                                 by=c("to"   = "name") )

  list(d=d.cor, p=p.cor, p.log=p.log, col=e.col, gr=g1.t, pair=p.pair, bin=g1.cls.bin, gr.raw=g1)
}



######## pathway, network, graph etc
#### build co-occuring network
#### x: input sample feature tibble
#### group: groups, first col: sample_id, 2nd col: group, can only have 2 or 3 groups
#### method: correlation method, e.g. pearson or spearman
#### p.cutoff: p.value cutoff, edges with p.value above this cutoff will be ignored
#### abs.cutoff abundance cutoff, to remove low abs features
#### prop.cutoff propotion cutoff, to remove rare features
#### rm.negative: ignore negative correlation
co.network.2or3.sample.types <- function(x, group, 
    method="pearson", p.cutoff = 0.05, rm.negative = F,
    abs.cutoff=0.01, prop.cutoff=0.5) {

  colnames(group)[2] = "GROUP"
  t.grp = sort(unique(group$GROUP))
  if ((length( t.grp ) > 3) || (length( t.grp ) < 2)) {
    return(NULL)
  }

  labs = colnames(x)[-1]
  d.sites=list()
  p.sites=list()
  p.min =  matrix(1, ncol=ncol(x)-1, nrow=ncol(x)-1, dimnames=list(labs, labs))
  for (t in t.grp) {

    df.cy = group %>% filter(GROUP == t) %>% select(1) %>% inner_join(x) %>% 
      reduce_zero_feature(cutoff = abs.cutoff) %>% reduce_rare_feature(cutoff = prop.cutoff)

    d.cor = cor(df.cy %>% select(-1), method = method)
    if (rm.negative) { #### remove negative correlation
      d.cor[ d.cor <0 ] = 0;
    }
   
    #### d.cor may have different dimesion from d.cor0
    #### merge sub matrix into main matrix !!!!
    d.cor0 = matrix(0, ncol=ncol(x)-1, nrow=ncol(x)-1, dimnames=list(labs, labs))
    d.cor0[match(colnames(d.cor), labs), match(colnames(d.cor), labs)] = d.cor

    d.cor = d.cor0
    p.cor = corr.p(d.cor, nrow(df.cy))$p #### only with lower triangle
    #### uppper is adjusted , now using un-adjusted p value
    #### so re-assign to 1 for upper
    p.cor[upper.tri(p.cor)] = 1
    p.cor = Matrix::forceSymmetric(p.cor, "L") #### copy lower triangle to uppper
    p.cor = as.matrix(p.cor)

    d.sites[[t]] = d.cor
    p.sites[[t]] = p.cor
    p.min = pmin(p.min, p.cor)
  }
  #### now p.min is min of all sample types
  p.cor = as.matrix(p.min)
  p.cor[ p.cor == 0       ] = min(p.cor[p.cor!=0])/10 #### assign min(p ij)/10 => pii
  p.cor[ p.cor > p.cutoff ] = 1
  #d.cor[ p.cor > p.cutoff ] = 0
  p.log = -log10(p.cor)
  diag(p.log) = 0 

  g1 = graph.adjacency(p.log, mode = "undirected", weighted = TRUE, diag = TRUE)
  #### Finding community structure by multi-level optimization of modularity
  g1.cls = cluster_louvain(g1)
  g1.t = tibble(name = g1.cls$name, idx =1:nrow(p.log), clstr=g1.cls$membership, degree=degree(g1))
  g1.cls.bin = g1.t %>% group_by(clstr) %>% summarise(binsize=length(name)) %>%
               arrange(desc(binsize)) %>% mutate(clstr_sorted = 1:max(g1.t$clstr))
  g1.t = g1.t %>% inner_join(g1.cls.bin)

  #### making a edge color mat
  e.col = matrix("white", ncol=nrow(g1.t), nrow=nrow(g1.t))
  color.key=list()
  for (i in 1:(nrow(g1.t)-1)) {
    for (j in (i+1):nrow(g1.t)) {
      p1 = p.sites[[t.grp[1]]][i,j]
      p2 = p.sites[[t.grp[2]]][i,j]
      p3 = 1
      if (length(t.grp) == 3) {
        p3 = p.sites[[t.grp[3]]][i,j]
      }
      if (p1 <p.cutoff && p2 <p.cutoff && p3<p.cutoff) {
        tc = "red"
        color.key[[tc]] = paste("significant in", t.grp[1], t.grp[2], t.grp[3], sep=" ") 
      } else if (p1 < p.cutoff && p2 < p.cutoff) {
        tc = "blue"
        color.key[[tc]] = paste("significant in", t.grp[1], t.grp[2],           sep=" ") 
      } else if (p1 < p.cutoff && p3 < p.cutoff) {
        tc = "green"
        color.key[[tc]] = paste("significant in", t.grp[1],           t.grp[3], sep=" ") 
      } else if (p2 < p.cutoff && p3 < p.cutoff) {
        tc = "cyan"
        color.key[[tc]] = paste("significant in",           t.grp[2], t.grp[3], sep=" ") 
      } else if (p1 < p.cutoff) {
        tc = "purple"
        color.key[[tc]] = paste("significant in", t.grp[1], sep=" ") 
      } else if (p2 < p.cutoff) {
        tc = "yellow"
        color.key[[tc]] = paste("significant in", t.grp[2], sep=" ") 
      } else if (p3 < p.cutoff) {
        tc = "brown"
        color.key[[tc]] = paste("significant in", t.grp[3], sep=" ") 
      } else {
        tc = "gray"
        color.key[[tc]] = "not significant"
      }
      e.col[i,j] = tc
      e.col[j,i] = tc
    }
  }
  list(p=p.cor, p.log=p.log, col=e.col, gr=g1.t, bin=g1.cls.bin, col.key=color.key)
}


#### regression to find bacteria load ratio
#### x feature table where row is taxa, column is samples
#### col_samples: columns of individual samples
#### col_pool:    column of the pooled sample
#### return fit, lm object 
fit_bac_load <- function(x, col_samples, col_pool) {
  # (ai,P - ai,2) r1,2 + (ai,P - ai,3) r1,3 + … + (ai,P - ai,m) r1,m = ai,1 - ai,P 
  y = x[, col_samples[1]] - x[, col_pool] 
  colnames(y)[1] = "y"
  
  for (i in col_samples[-1]) {
    y = y %>% cbind( x[, col_pool] - x[, i])
    colnames(y)[ncol(y)] = colnames(x)[i]
  }
  fit = lm(y ~ ., data = y)
  fit
}




#### Notes:

######## pipe into read_xxx
#### t1 = read_general_tibble(pipe("cut -f 1,3- sample.list.RGI/filtered.sample.RGI.tsv")  )$x %>% t1_lab

######## increase font size when save ggplot plots
#### t=theme_get()
#### t$text$size = 14 #### default size is 11
#### theme_set(t)
#### feature_barplot() etc.

######## network format convert
####  save igraph obj to gexf format, which can be opened by Gephi etc
#### t.net = co.network.two.omic.types(df, df.cy, names=c("Bacteria","Cytokine"), p.cutoff=0.05, rm.negative=T )
#### cg2 = igraph.to.gexf( t.net$gr.raw )
#### print(cg2, file="/Users/wli/zz-baboon-sp0.001-cy.gexf")



#### microbiome 
#### report functions

#### x a vector of feature, e.g. diversity
#### value of this feature of a subject 
#### plot histogram of distribution of x and point the subject
#### bg.range -back ground fill with color (bg.range.color) to show 
####   range of value 
####   if not NULL, bg.range = list(`Normal range`=c(-Inf, 2.2), Dysbiotic=c(2.2, Inf))
####          bg.range.color = c("#FFBBBB",    "#BBFFBB") 
####          bg.text.color  = c("#222222",    "#222222") 
report.histogram.with.subject <- function(x, bins=30, labx=NULL, laby="Density", subject=NULL, 
                                          bg.range=NULL, bg.range.color=NULL, bg.text.color=NULL, ann_text_size=4, percent_unit=F) {
  d = density(x, n=length(x))
  density.max = max(d$y)
  m1 = median(x)
  small.v = m1
  if (! is.null(subject)) {
    if (subject < small.v) {
      small.v = subject
    }
  }
  small.v = small.v - as.integer(small.v)
  i = 1
  j = 1
  if (small.v > 0) {
    i = -as.integer( log10(small.v) )
    j = 10 ** i * 100
  }

  m1.s = as.integer(m1 * j) / j
  if (percent_unit) {
    m1.s = m1.s * 100
    m1.s = paste(m1.s, "%", sep="")
  }
  sm.arrow = arrow(length = unit(0.2, "cm"), ends="first", type="open")

  p1 = ggplot(tibble(v = x), aes(x=v))

  if (! is.null(bg.range)) {
    for (i in 1:length(bg.range)) {
      i.name = names(bg.range[i])
      x.range = bg.range[i] %>% unlist()
      x.text = x.range[1]
      just1 = 0
      if (is.infinite( x.text)) {
        x.text = x.range[2]
        just1 = 1
      }
      c.fill = "#BBBBBB"
      c.text = "#222222"
      if (! is.null(bg.range.color))  c.fill = bg.range.color[i]
      if (! is.null(bg.text.color ))  c.text = bg.text.color[i]
      p1 = p1 + annotate("rect", xmin = x.range[1], xmax=x.range[2], ymin = -Inf, ymax = Inf, fill = c.fill, alpha = .2) +
                annotate("text", x    = x.text,     y=1.3, label = paste(" ", i.name, " ", sep=""), hjust = just1, vjust = 0, color=c.text, size=ann_text_size)
    }
  }

  p1 = p1 +
    geom_histogram(aes(y=stat(count / max(count))), fill="#DDDDFF", color="#AAAACC", bins=bins) +
    geom_line(data=tibble(x=d$x, y=d$y / density.max), aes(x=x, y=y), color="#8888AA") + 
    annotate("segment", x=m1, xend=m1, y=0, yend=1.1, color = "#2222BB", size=0.5, arrow=sm.arrow) + 
    annotate("text", x = m1, y=1.1, label = paste(" Population Median ", m1.s, sep=""), hjust = 0, color="#2222BB", size=ann_text_size) +
    labs(x=labx, y=laby) + 
    theme_classic() + 
    theme(axis.ticks.y = element_blank(), axis.text.y = element_blank())

  if (! is.null(subject)) {
    subject.s = as.integer(subject * j) / j
    if (percent_unit) {
      subject.s = subject.s * 100
      subject.s = paste(subject.s, "%", sep="")
    }
    p1 = p1 + annotate("segment", x=subject, xend=subject, y=0, yend=1.2, color = "#22BB22", size=0.5, arrow=sm.arrow) +
      annotate("text", x = subject, y=1.2, label = paste(" Subject ", subject.s, sep=""), hjust = 0,color = "#22BB22", size=ann_text_size)
  }

  p1
} 


#### enterotype plot
#### x tibble of genus abundance, filtered
#### sample_group is sample bin, bin is enterotype bin
#### subject is tibble of genus abundance of a subject to be displayed in the PCA plot
report.enterotype.with.subject <- function(x, sample_group, labx="Principal component 1", laby="Principal component 2", 
                                           subject=NULL, ann_text_size=4) {
  colnames(x)[1] = "sample_id"
  set.seed(42)
  df = x

  ## PCA
  ## pca = PCA(x %>% dplyr::select(-1), scale.unit = F, graph = F)
  ## y.df = cbind( tibble(sample_id=x$sample_id), pca$ind$coord)
  ## PRCOMP
  pca = prcomp(x %>% dplyr::select(-1), scale. = F)
  y.df = cbind( tibble(sample_id=x$sample_id), pca$x[, 1:2])
  y.df = sample_group %>% dplyr::select(1,2) %>% inner_join(y.df)
  colnames(y.df)[2] = "group"
  colnames(y.df)[3] = "Dim.1"
  colnames(y.df)[4] = "Dim.2"
  
  g = ggplot(y.df, aes(x=Dim.1, y=Dim.2, colour=group)) +
    geom_point(size=0.8) + scale_colour_manual(values = c("red", "blue", "orange"))
  #scale_colour_manual(values = mycol(3, pal.set="Dark2"))
  
  if (! is.null(subject)) {
    f1 = colnames(x)[-1]
    sub.x = tibble_bind_rows(subject, x[1:2, ]) %>% dplyr::select(c("sample_id", f1))
    # x.trans = (sub.x %>% select(-1) %>% as.matrix() %*% pca$rotation)[, 1:2] %>% as_tibble()
    x.trans = (predict(pca, sub.x))[, 1:2] %>% as_tibble() 
    x.trans = x.trans[1:(nrow(subject)), ]
    colnames(x.trans) = c("Dim.1", "Dim.2")
    x_sub = x.trans$Dim.1[1]
    y_sub = x.trans$Dim.2[1]
    g = g + geom_point(data = x.trans, aes(x=Dim.1, y=Dim.2), color = "#22BB22", size=1.5) +
      annotate("text", x = x_sub, y=y_sub, label = " Subject", hjust = 0,color = "#22BB22", size=ann_text_size)

  }
  
  g = g + labs(x=labx, y=laby) +
    theme_classic() +
    guides(colour = guide_legend(title="Enterotype")) +
    theme(axis.ticks.y = element_blank(), axis.text.y = element_blank() ) +
    theme(axis.ticks.x = element_blank(), axis.text.x = element_blank() ) 
  g
}


report.species_table <- function(subject, ref, ref_info, cutoff = 0.0001) {
  subject = subject %>% reduce_zero_feature(cutoff = cutoff)
  intersect.sp = intersect(colnames(subject), colnames(ref) )
  refx = ref     %>% dplyr::select(intersect.sp) 
  subx = subject %>% dplyr::select(intersect.sp)
  num_ref = nrow(ref)

  x.info = refx %>% feature_info() %>% dplyr::select(name, median, occur) %>%
           mutate(prevalence = occur / num_ref ) %>% 
           dplyr::select(-occur)

  refx.plus.sub = subx %>% rbind(refx)
  tile = refx %>% dplyr::select(-1)  %>% apply(2, function(x) {i=x[1]; y=x[-1]; sum(y < i) / num_ref} )
  x.info = x.info %>% mutate(Percentile = tile)

  subject.t = tibble_t(subject)
  colnames(subject.t)[2] = "Abundance"

  y = subject.t %>% left_join(x.info) %>% left_join(ref_info %>% dplyr::select(name, tax_id, superkingdom) )
  y = y %>% mutate(Abundance = as.integer(Abundance * 10000)/100,  
                   median    = as.integer(median    * 10000)/100,
                   prevalence= as.integer(prevalence* 100) /1,
                   Percentile= as.integer(Percentile* 100) /1) %>% arrange(desc(Abundance)) %>%
            dplyr::select(tax_id, superkingdom, name, Abundance, median, prevalence,Percentile  )

  colnames(y) = c("Taxonomy ID", "Domain", "Species","Abundance (%)", "Population median abundance (%)",         
                          "Population prevalence (%)", "Percentile in population (%)")
  y
}


report.rgi_table <- function(subject, ref, cutoff = 1) {
  all.rgi =   colnames(ref)[-1]
  subx = subject %>% dplyr::select(c("sample_id", all.rgi))
  num_ref = nrow(ref)
    
  x.info = ref %>% feature_info() %>% dplyr::select(name, median, occur) %>%
      mutate(prevalence = occur / num_ref ) %>%
      dplyr::select(-occur)
  ref.plus.sub = subx %>% rbind(ref)

  tile = ref %>% dplyr::select(-1)  %>% apply(2, function(x) {i=x[1]; y=x[-1]; sum(y < i) / num_ref} )
  x.info = x.info %>% mutate(Percentile = tile)
    
  subject.t = tibble_t(subject)
  colnames(subject.t)[2] = "Abundance"
    
    y = subject.t %>% left_join(x.info)
    y = y %>% mutate(Abundance = as.integer(Abundance * 10000)/100,
                     median    = as.integer(median    * 10000)/100,
                     prevalence= as.integer(prevalence* 100) /1,
                     Percentile= as.integer(Percentile* 100) /1) %>% arrange(desc(Abundance)) %>%
    dplyr::select(name, Abundance, median, prevalence,Percentile  )
    
    colnames(y) = c("Antibiotic drug class","Abundance (CPM)", "Population median abundance (CPM)",
                    "Population prevalence (%)", "Percentile in population (%)")
    y
}

#### read in a mash distence file generated by mash dist
dist_2_dendro <- function(dist_f) {
  this.dist = read_tsv(dist_f) %>% select(-1)
  ## format of taxid|1622269|NZ_KQ236688.1
  new_names = sub("taxid\\|(\\d+)\\|.+", "\\1", colnames(this.dist), perl=T)  #### to taxid
  this.dist = this.dist %>% as.matrix()
  colnames(this.dist) = new_names
  rownames(this.dist) = new_names

  this.cls = hclust(this.dist.mat %>% as.dist())
  as.dendrogram(this.cls)
}


